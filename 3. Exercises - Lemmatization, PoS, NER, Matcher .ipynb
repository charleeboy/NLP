{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "variable-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/charleeboy/opt/anaconda3/envs/ex/bin/python: can't open file 'conda': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} conda install Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "valid-consultation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:32:23.755820Z",
     "start_time": "2021-03-30T19:32:22.644310Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-mortgage",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "**Exercise 1.1**\n",
    "\n",
    "You are given the words \"playing\", \"played\", \"play\". Find the lemma using spaCy for all of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "english-plate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:34:20.464484Z",
     "start_time": "2021-03-30T19:34:20.425793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lemma of the word 'playing' is play\n",
      "The lemma of the word 'played' is play\n",
      "The lemma of the word 'playing' is play\n"
     ]
    }
   ],
   "source": [
    "words = [\"playing\", \"played\", \"playing\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-commonwealth",
   "metadata": {},
   "source": [
    "**Exercise 1.2**\n",
    "\n",
    "Assign the spaCy lemmatizer to a variable instead of using the whole `nlp` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-champion",
   "metadata": {},
   "source": [
    "**Exercise 1.3**\n",
    "\n",
    "Find the verb, the noun and the adjective forms of the words: \"playing\", \"played\", \"surfing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "elementary-blood",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:41:42.605031Z",
     "start_time": "2021-03-30T19:41:42.595092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['play']\n",
      "['playing']\n",
      "['playing']\n",
      "-----------\n",
      "['play']\n",
      "['played']\n",
      "['played']\n",
      "-----------\n",
      "['surf']\n",
      "['surfing']\n",
      "['surfing']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "documentary-heart",
   "metadata": {},
   "source": [
    "## Spell Checker\n",
    "\n",
    "**Exercise 1.4**\n",
    "\n",
    "In the following sentences there are some mispelling errors. Can you preprocess them to get rid of them? \n",
    "\n",
    "*N.B. there's no perfect spell-checker. Don't waste time on this. But be aware that it can be useful sometimes.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caroline-agency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T20:10:59.239954Z",
     "start_time": "2021-03-30T20:10:59.087475Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-968c99b33683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mspell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ex/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;31m#call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \"\"\"\n\u001b[0;32m--> 978\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ex/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1058\u001b[0m                 \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE088\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             )\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     def update(\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got list)"
     ]
    }
   ],
   "source": [
    "sentences = [\"i realy like this exerxise\", \n",
    "             \"tis sentences are surely writen by an italian\",\n",
    "             \"lets fix thissssss\"\n",
    "            ]\n",
    "\n",
    "\n",
    "\n",
    "text = nlp(sentences)\n",
    "spell = SpellChecker()\n",
    "\n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown([token.text for token in text])\n",
    "\n",
    "\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    "\n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-imperial",
   "metadata": {},
   "source": [
    "## POS Tagging\n",
    "\n",
    "**Exercise 1.5 (★☆☆)**\n",
    "\n",
    "The training of TAs to survive the first two weeks at Strive School consists of the following sets:\n",
    "\n",
    "- 1000 reps of \"Did you google it?\"\n",
    "- 1000 reps of \"Did you search it on Google already?\"\n",
    "\n",
    "Use spaCy to explain the difference of the word \"google\" in the two sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "respiratory-priest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:57:52.063503Z",
     "start_time": "2021-03-31T04:57:51.819028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google verb, base form\n",
      "Google noun, proper singular\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "pattern = [{\"LOWER\": \"google\"}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"G\", [pattern])\n",
    "sentences = [\"Did you google it?\",\n",
    "             \"Did you search it on Google already?\"]\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(str(sentences))\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    print(span.text,spacy.explain((doc[start].tag_)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-iceland",
   "metadata": {},
   "source": [
    "**Exercise 1.5 (★★☆)**\n",
    "\n",
    "Get the frequencies of the POS tags in the example sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "rational-xerox",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:17:13.245020Z",
     "start_time": "2021-03-31T05:17:13.220428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DET     : 3\n",
      "AUX     : 1\n",
      "NOUN    : 3\n",
      "PUNCT   : 2\n",
      "SPACE   : 1\n",
      "PROPN   : 2\n",
      "ADP     : 1\n",
      "PRON    : 1\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"This is an example sentence.\n",
    "            Count the POS tags in it.\"\"\"\n",
    "doc = nlp(str(sentence))\n",
    "num_pos = doc.count_by(spacy.attrs.POS)\n",
    "\n",
    "\n",
    "for ID, frequency in num_pos.items():\n",
    "    print(f\"{doc.vocab[ID].text:{8}}: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-label",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:09:39.399233Z",
     "start_time": "2021-03-31T05:09:39.364673Z"
    }
   },
   "source": [
    "**Exercise 1.7 (★★★)**\n",
    "\n",
    "(This exercises requires many steps in Pandas, no unique solution. You can hard code the name of the columns for this example if you get stuck.)\n",
    "\n",
    "Loading 10 tweets from the twitter datasets, create a dataframe containing the frequencies of each POS per tweet (see example).\n",
    "\n",
    "N.B. The column names must be the tags not the indices of the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fifth-dispute",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:16:19.616337Z",
     "start_time": "2021-03-31T06:16:19.498649Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/stock_data.csv\")\n",
    "\n",
    "df = df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "outstanding-commonwealth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:16:19.660774Z",
     "start_time": "2021-03-31T06:16:19.656353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1\n",
       "5                                  PGNX  Over 3.04            1\n",
       "6  AAP - user if so then the current downtrend wi...         -1\n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1\n",
       "8  GOOG - ower trend line channel test & volume s...          1\n",
       "9             AAP will watch tomorrow for ONG entry.          1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "median-discrimination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:26:12.875138Z",
     "start_time": "2021-03-31T05:26:12.865565Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "juvenile-paris",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:34:40.175145Z",
     "start_time": "2021-03-31T05:34:39.994609Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "tropical-detective",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:34:45.822225Z",
     "start_time": "2021-03-31T05:34:45.814005Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['NOUN',\n",
    " 'ADP',\n",
    " 'DET',\n",
    " 'PROPN',\n",
    " 'SPACE',\n",
    " 'NUM',\n",
    " 'CCONJ',\n",
    " 'PUNCT',\n",
    " 'VERB',\n",
    " 'SYM',\n",
    " 'ADV',\n",
    " 'PRON',\n",
    " 'AUX',\n",
    " 'ADJ',\n",
    " 'PART',\n",
    " 'SCONJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "collective-missouri",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.001480Z",
     "start_time": "2021-03-31T05:50:56.992453Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array = np.zeros((10,len(columns)+1))\n",
    "data = pd.DataFrame(array, columns=[\"text\", *columns])\n",
    "data['text'] = data['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "sublime-trade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.097425Z",
     "start_time": "2021-03-31T05:50:57.080979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>DET</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>SYM</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRON</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PART</th>\n",
       "      <th>SCONJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text  NOUN  ADP  DET  PROPN  SPACE  NUM  CCONJ  PUNCT  VERB  SYM  ADV  PRON  \\\n",
       "0  0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0   \n",
       "1  0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0   \n",
       "2  0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0   \n",
       "3  0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0   \n",
       "4  0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0   \n",
       "5  0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0   \n",
       "6  0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0   \n",
       "7  0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0   \n",
       "8  0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0   \n",
       "9  0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0   \n",
       "\n",
       "   AUX  ADJ  PART  SCONJ  \n",
       "0  0.0  0.0   0.0    0.0  \n",
       "1  0.0  0.0   0.0    0.0  \n",
       "2  0.0  0.0   0.0    0.0  \n",
       "3  0.0  0.0   0.0    0.0  \n",
       "4  0.0  0.0   0.0    0.0  \n",
       "5  0.0  0.0   0.0    0.0  \n",
       "6  0.0  0.0   0.0    0.0  \n",
       "7  0.0  0.0   0.0    0.0  \n",
       "8  0.0  0.0   0.0    0.0  \n",
       "9  0.0  0.0   0.0    0.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "designed-mobile",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.313768Z",
     "start_time": "2021-03-31T05:50:57.211856Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    doc = nlp(str(row['Text']))\n",
    "    num_pos = doc.count_by(spacy.attrs.POS)\n",
    "    data.at[index, \"text\"] = row['Text']\n",
    "\n",
    "\n",
    "    for ID, frequency in num_pos.items():\n",
    "    #    print(f\"{row['Text']}:{doc.vocab[ID].text:{8}}: {frequency}\")\n",
    "        ds = data.iloc[[index]]\n",
    "        voc= str(doc.vocab[ID].text)\n",
    "        ds.loc[voc]=frequency\n",
    "        data.at[index, voc] = frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "formed-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>DET</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>SYM</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRON</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PART</th>\n",
       "      <th>SCONJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  NOUN  ADP  DET  PROPN  \\\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...   7.0  1.0  0.0    7.0   \n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...   6.0  2.0  2.0    5.0   \n",
       "2  user I'd be afraid to short AMZN - they are lo...   4.0  3.0  2.0    2.0   \n",
       "3                                  MNTA Over 12.00     1.0  1.0  0.0    0.0   \n",
       "4                                   OI  Over 21.37     0.0  1.0  0.0    1.0   \n",
       "5                                  PGNX  Over 3.04     1.0  1.0  0.0    0.0   \n",
       "6  AAP - user if so then the current downtrend wi...   7.0  1.0  2.0    0.0   \n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...   1.0  0.0  0.0   12.0   \n",
       "8  GOOG - ower trend line channel test & volume s...   7.0  0.0  0.0    0.0   \n",
       "9             AAP will watch tomorrow for ONG entry.   3.0  1.0  0.0    1.0   \n",
       "\n",
       "   SPACE  NUM  CCONJ  PUNCT  VERB  SYM  ADV  PRON  AUX  ADJ  PART  SCONJ  \n",
       "0    1.0  2.0    1.0    1.0   1.0  0.0  0.0   1.0  0.0  0.0   0.0    0.0  \n",
       "1    2.0  2.0    0.0    4.0   0.0  1.0  1.0   0.0  0.0  0.0   0.0    0.0  \n",
       "2    0.0  0.0    1.0    5.0   2.0  0.0  0.0   2.0  3.0  3.0   0.0    0.0  \n",
       "3    1.0  1.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "4    2.0  1.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "5    2.0  1.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "6    0.0  0.0    0.0    5.0   1.0  0.0  4.0   0.0  1.0  3.0   0.0    1.0  \n",
       "7    1.0  0.0    0.0    1.0   0.0  0.0  0.0   0.0  0.0  1.0   1.0    0.0  \n",
       "8    1.0  1.0    1.0    2.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "9    0.0  0.0    0.0    1.0   1.0  0.0  0.0   0.0  1.0  0.0   0.0    0.0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-terminology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.385440Z",
     "start_time": "2021-03-31T05:50:57.369822Z"
    },
    "scrolled": true
   },
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-allowance",
   "metadata": {},
   "source": [
    "## Named Entities Recognition\n",
    "\n",
    "**Exercise 1.8**\n",
    "\n",
    "In the Twitter dataset sample above, count how many entities are in each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "smooth-chrome",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:19:13.644167Z",
     "start_time": "2021-03-31T06:19:13.559490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  ents\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1   4.0\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1   4.0\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1   2.0\n",
       "3                                  MNTA Over 12.00            1   2.0\n",
       "4                                   OI  Over 21.37            1   0.0\n",
       "5                                  PGNX  Over 3.04            1   1.0\n",
       "6  AAP - user if so then the current downtrend wi...         -1   0.0\n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1   3.0\n",
       "8  GOOG - ower trend line channel test & volume s...          1   0.0\n",
       "9             AAP will watch tomorrow for ONG entry.          1   2.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/stock_data.csv\")\n",
    "\n",
    "df = df.iloc[:10]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    doc = nlp(str(row['Text']))\n",
    "    df.at[index, \"ents\"] =len(doc.ents)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "noticed-honor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:18:11.584150Z",
     "start_time": "2021-03-31T06:18:11.571558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  ents\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1     3\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1     5\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1     1\n",
       "3                                  MNTA Over 12.00            1     1\n",
       "4                                   OI  Over 21.37            1     1\n",
       "5                                  PGNX  Over 3.04            1     2\n",
       "6  AAP - user if so then the current downtrend wi...         -1     1\n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1     3\n",
       "8  GOOG - ower trend line channel test & volume s...          1     1\n",
       "9             AAP will watch tomorrow for ONG entry.          1     3"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-method",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:18:48.877669Z",
     "start_time": "2021-03-31T06:18:48.859874Z"
    }
   },
   "source": [
    "**Exercise 1.9**\n",
    "\n",
    "In the Twitter dataset sample above, create an extra column with the name of the Organization entities in the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ceramic-accordance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:20:28.240476Z",
     "start_time": "2021-03-31T06:20:28.227574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Organizations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "      <td>PNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "      <td>AWESOME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>AMZN,eBooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>PGNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NYX WIN TIE TAP ICE INT BMC,CHK BIIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "      <td>ONG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  \\\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1   \n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1   \n",
       "2  user I'd be afraid to short AMZN - they are lo...          1   \n",
       "3                                  MNTA Over 12.00            1   \n",
       "4                                   OI  Over 21.37            1   \n",
       "5                                  PGNX  Over 3.04            1   \n",
       "6  AAP - user if so then the current downtrend wi...         -1   \n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1   \n",
       "8  GOOG - ower trend line channel test & volume s...          1   \n",
       "9             AAP will watch tomorrow for ONG entry.          1   \n",
       "\n",
       "                          Organizations  \n",
       "0                                   PNK  \n",
       "1                               AWESOME  \n",
       "2                           AMZN,eBooks  \n",
       "3                                        \n",
       "4                                        \n",
       "5                                  PGNX  \n",
       "6                                        \n",
       "7  NYX WIN TIE TAP ICE INT BMC,CHK BIIB  \n",
       "8                                        \n",
       "9                                   ONG  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/stock_data.csv\")\n",
    "\n",
    "df = df.iloc[:10]\n",
    "df[\"Organizations\"] =\"\"\n",
    "for index, row in df.iterrows():\n",
    "    doc = nlp(str(row['Text']))\n",
    "  \n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_==\"ORG\":\n",
    "            if df.at[index, \"Organizations\"] ==\"\":\n",
    "                df.at[index, \"Organizations\"] = ent.text\n",
    "            else:\n",
    "                df.at[index, \"Organizations\"] =  df.at[index, \"Organizations\"]+ \",\"  + ent.text\n",
    "df          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-island",
   "metadata": {},
   "source": [
    "## Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-guyana",
   "metadata": {},
   "source": [
    "**Exercise 2.0**\n",
    "\n",
    "You have scraped many websites collecting a list of users but written in many different form: someone has an email like:\n",
    "\n",
    "```\n",
    "username: antonio\n",
    "user: antonio.marsella@email.com\n",
    "USER:antonio\n",
    "USERNAME: antonio\n",
    "```\n",
    "How would you match all of them using a spaCy matcher?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "little-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "username: antonio\n",
    "user: antonio.marsella@email.com\n",
    "USER:antonio\n",
    "USERNAME: antonio\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "domestic-footage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:48:55.806530Z",
     "start_time": "2021-03-31T06:48:55.729472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 username: antonio\n",
      "5 8 user: antonio.marsella@email.com\n",
      "9 12 USER:antonio\n",
      "13 16 USERNAME: antonio\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "pattern1 =[ {\"TEXT\":\"username\"},{\"IS_PUNCT\": True},\n",
    "             {}\n",
    "]\n",
    "pattern2=[ {\"TEXT\":\"USER\"},{\"IS_PUNCT\": True},\n",
    "             {}\n",
    "]\n",
    "pattern3 =[{\"TEXT\":\"user\"},{\"IS_PUNCT\": True},{\"TEXT\": {\"REGEX\": \"[a-z0-9\\.\\-+_]+ *@[a-z0-9\\.\\-+_]+\"}}]\n",
    "pattern4=[ {\"TEXT\":\"USERNAME\"},{\"IS_PUNCT\": True},\n",
    "             {}\n",
    "]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"Username-p\", [pattern1])\n",
    "matcher.add(\"USER-p\", [pattern2])\n",
    "matcher.add(\"email-p\", [pattern3])\n",
    "matcher.add(\"USERNAME-p\", [pattern4])\n",
    "\n",
    "\n",
    "\n",
    "doc = nlp(str(text))\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    rule_id = nlp.vocab.strings[match_id]  \n",
    "    span = doc[start : end]  # get the matched slice of the doc\n",
    "    print(start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-speaker",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ex)",
   "language": "python",
   "name": "ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
